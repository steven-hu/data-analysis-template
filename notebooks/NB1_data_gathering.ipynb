{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook, you'll\n",
      "\n",
      "* create the directory structure for your project\n",
      "* download the raw data for your project\n",
      "* **write functions and classes to transform raw data (e.g in XML, jason, etc.) into data frames**\n",
      "* explain what your are doing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Team members responsible for this notebook:\n",
      "\n",
      "List the team members contributing to this notebook, along with their responsabilities:\n",
      "\n",
      "* team member 1 **name**: team member 1 **responsabilities**\n",
      "* team member 2 **name**: team member 2 **responsabilities**\n",
      "* etc.\n",
      "\n",
      "I advise you to work at least in pairs for each project notebook, as you did for the homework assignments. Of course, all team members may participate to each notebook. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Instructions:\n",
      "\n",
      "In **markdown cells**, you'll\n",
      "\n",
      "* list and describe the data sources for your class project\n",
      "    * provide the data urls\n",
      "    * describe the file formats\n",
      "    * explain the data content of each file\n",
      "   \n",
      "**Remark:** If your data is not directly available through the web (for instance, you requested it from a company, or got it from Inna or Henry), place you data into your personal bdrive, and provide a link to it, that you'll use in this notebook to download it into the data folder, as explained below).\n",
      "\n",
      "\n",
      "In **code cells**, you'll\n",
      "\n",
      "* create the following directories:\n",
      "\n",
      "        ./data\n",
      "        ./data/raw        # to store your raw data\n",
      "        ./data/cleaned    # to store the cleanned data\n",
      "        ./data/simulated  # to store simulated data\n",
      "        ./visualizations  # to store your plots\n",
      "\n",
      "\n",
      "* display samples of your data files (e.g. for a csv files, use data frames and the <code>head</code> method)\n",
      "\n",
      "\n",
      "*  Write **scripts** into the <code>./script</code> directory using the he **magic command** \n",
      "\n",
      "    %%file ./script/file_name\n",
      "    \n",
      "Your scripts should contain **functions** and **objects** allowing you to\n",
      "\n",
      "* download the actual raw data in the directory <code>./data/raw</code>\n",
      "\n",
      "\n",
      "* load the downloaded the raw data files into data frames\n",
      "\n",
      "This way, the functions and objects contained in your scripts will be accessible in other notebooks through the <code>import</code> command in Python (see example below).\n",
      "\n",
      "\n",
      "**Remark 1:** In the code cells, you may use Python, R, or Bash, as you find more convenient.\n",
      "\n",
      "\n",
      "**Remark 2:** Try to make your notebook as readable and usable (by others) as possible."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is an example of how to package your code into scripts reusable in other notebook.\n",
      "\n",
      "You'll need to do something similar to that. You'll also need to write explanations as outlined above in markdown cells."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Creating the directory structure"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Downloading and displaying raw data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this example, I am using R. You want to use Python instead."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**TO DO:** list sources, display data sample, explain data content, etc. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now download an XML source containing plant data, and display an typical plant entry, represented as a XML node:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "library(XML)\n",
      "plant_url  =  'http://www.stat.berkeley.edu/classes/s133/data/plant_catalog.xml'\n",
      "plant_file = './data/raw/plant.xml'\n",
      "\n",
      "download.file(plant_url, plant_file, method=\"curl\")\n",
      "\n",
      "xml_doc   = xmlParse(plant_file)\n",
      "root_node = xmlRoot(xml_doc)\n",
      "\n",
      "plant_nodes = xmlChildren(root_node)\n",
      "print(plant_nodes[[1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\n",
        "Attaching package: \u2018XML\u2019\n",
        "\n",
        "The following object(s) are masked from \u2018package:tools\u2019:\n",
        "\n",
        "    toHTML\n",
        "\n",
        "<PLANT>\n",
        "  <COMMON>Bloodroot</COMMON>\n",
        "  <BOTANICAL>Sanguinaria canadensis</BOTANICAL>\n",
        "  <ZONE>4</ZONE>\n",
        "  <LIGHT>Mostly Shady</LIGHT>\n",
        "  <PRICE>$2.44</PRICE>\n",
        "  <AVAILABILITY>031599</AVAILABILITY>\n",
        "</PLANT> \n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Loading raw data into data frames"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataframe column labels are the tags of the XML nodes, contained in the plant XML nodes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "\n",
      "column_names = names(plant_nodes[[1]])\n",
      "cat(column_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "COMMON BOTANICAL ZONE LIGHT PRICE AVAILABILITY"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given a column name, we create a data frame column containing the column values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "common_tag = column_names[1]\n",
      "\n",
      "get_value = function(plant_node, tag) xmlValue(plant_node[[tag]])\n",
      "    \n",
      "common_column = sapply(plant_nodes, get_value, common_tag)\n",
      "    \n",
      "cat(common_column)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "Bloodroot Columbine Marsh Marigold Cowslip Dutchman's-Breeches Ginger, Wild Hepatica Liverleaf Jack-In-The-Pulpit Mayapple Phlox, Woodland Phlox, Blue Spring-Beauty Trillium Wake Robin Violet, Dog-Tooth Trout Lily Adder's-Tongue Anemone Grecian Windflower Bee Balm Bergamot Black-Eyed Susan Buttercup Crowfoot Butterfly Weed Cinquefoil Primrose Gentian Blue Gentian Jacob's Ladder Greek Valerian California Poppy Shooting Star Snakeroot Cardinal Flower"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We package the code above into a function that creates the data frame column corresponding from a tag name and a list of plant nodes: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "get_column = function(tag, plants) sapply(plants, get_value, tag)\n",
      "    \n",
      "cat((get_column('COMMON', plant_nodes)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "Bloodroot Columbine Marsh Marigold Cowslip Dutchman's-Breeches Ginger, Wild Hepatica Liverleaf Jack-In-The-Pulpit Mayapple Phlox, Woodland Phlox, Blue Spring-Beauty Trillium Wake Robin Violet, Dog-Tooth Trout Lily Adder's-Tongue Anemone Grecian Windflower Bee Balm Bergamot Black-Eyed Susan Buttercup Crowfoot Butterfly Weed Cinquefoil Primrose Gentian Blue Gentian Jacob's Ladder Greek Valerian California Poppy Shooting Star Snakeroot Cardinal Flower"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now ready to retrieve all the columns of our data frame into a list of vectors, which we will use to construct our data frame:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "data = lapply(column_names, get_column, plant_nodes)\n",
      "\n",
      "plant_df = data.frame(data, stringsAsFactors = FALSE)\n",
      "\n",
      "print(head(plant_df))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "               COMMON              BOTANICAL ZONE        LIGHT PRICE\n",
        "1           Bloodroot Sanguinaria canadensis    4 Mostly Shady $2.44\n",
        "2           Columbine   Aquilegia canadensis    3 Mostly Shady $9.37\n",
        "3      Marsh Marigold       Caltha palustris    4 Mostly Sunny $6.81\n",
        "4             Cowslip       Caltha palustris    4 Mostly Shady $9.90\n",
        "5 Dutchman's-Breeches    Dicentra cucullaria    3 Mostly Shady $6.44\n",
        "6        Ginger, Wild       Asarum canadense    3 Mostly Shady $9.03\n",
        "  AVAILABILITY\n",
        "1       031599\n",
        "2       030699\n",
        "3       051799\n",
        "4       030699\n",
        "5       012099\n",
        "6       041899\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the data frame we just created, we save the plant data into a csv file into the raw data directory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "write.csv(plant_df, './data/raw/plants_to_be_cleaned.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head ./data/raw/plants_to_be_cleaned.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Packaging the gathering code into reusable functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file ./script/plant_df-R\n",
      "\n",
      "get_value  = function(plant_node, tag) xmlValue(plant_node[[tag]])\n",
      "    \n",
      "get_column = function(tag, plants) sapply(plants, get_value, tag)\n",
      "    \n",
      "create_df_from_plant_xml = function(plant_file){\n",
      "    require(XML)\n",
      "    xml_doc      = xmlParse(plant_file)\n",
      "    root_node    = xmlRoot(xml_doc)\n",
      "    plant_nodes  = xmlChildren(root_node)\n",
      "    column_names = names(plant_nodes[[1]])\n",
      "\n",
      "    data     = lapply(column_names, get_column, plant_nodes)\n",
      "    return(data.frame(data, stringsAsFactors = FALSE))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing ./script/plant_df-R\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, our function converting a raw plant XML file into a R data frame can be used in other notebooks, using the <code>source</code> command:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "source('./script/plant_df-R')\n",
      "\n",
      "print(head(create_df_from_plant_xml(plant_file)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "               COMMON              BOTANICAL ZONE        LIGHT PRICE\n",
        "1           Bloodroot Sanguinaria canadensis    4 Mostly Shady $2.44\n",
        "2           Columbine   Aquilegia canadensis    3 Mostly Shady $9.37\n",
        "3      Marsh Marigold       Caltha palustris    4 Mostly Sunny $6.81\n",
        "4             Cowslip       Caltha palustris    4 Mostly Shady $9.90\n",
        "5 Dutchman's-Breeches    Dicentra cucullaria    3 Mostly Shady $6.44\n",
        "6        Ginger, Wild       Asarum canadense    3 Mostly Shady $9.03\n",
        "  AVAILABILITY\n",
        "1       031599\n",
        "2       030699\n",
        "3       051799\n",
        "4       030699\n",
        "5       012099\n",
        "6       041899\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Gathering (OUR STUFF STARTS HERE)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Creating Directory Structure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "mkdir ../script ../data ../data/raw ../data/cleaned ../data/simulated ../visualizations\n",
      "ls -r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "README.md\n",
        "NB4_project_report.ipynb\n",
        "NB3_data_analysis.ipynb\n",
        "NB2_data_cleaning.ipynb\n",
        "NB1_data_gathering.ipynb\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Description of the Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We pulled flight data from 1987 to 2008 from http://stat-computing.org/dataexpo/2009/the-data.html, downloading all 20 years. The data came in archived/compressed .csv files (comma-separated variables)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The files contain data on domestic US flights from 1987 to 2008. The data from all years combined consist of over 100 million rows and 29 columns. Each row represents a flight. The columns include (but are not limited to) the following information:\n",
      "\n",
      "* Year\n",
      "* Month\n",
      "* Day of Month\n",
      "* Day of Week\n",
      "* Scheduled Departure Time\n",
      "* Actual Departure Time\n",
      "* Scheduled Arrival Time\n",
      "* Actual Arrival Time\n",
      "* Scheduled Flight Time\n",
      "* Actual Flight Time\n",
      "* Departure Delay\n",
      "* Arrival Delay\n",
      "* Airport of Origin\n",
      "* Destination Airport\n",
      "* Flight Distance\n",
      "* Flight Number"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Downloading the Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#note: don't run this stuff unless you're really sure, the files are large\n",
      "\n",
      "#cd ../data/raw\n",
      "#wget http://stat-computing.org/dataexpo/2009/1987.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1988.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1989.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1990.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1991.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1992.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1993.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1994.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1995.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1996.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1997.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1998.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/1999.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2000.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2001.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2002.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2003.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2004.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2005.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2006.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2007.csv.bz2\n",
      "#wget http://stat-computing.org/dataexpo/2009/2008.csv.bz2\n",
      "#bunzip2 1987.csv.bz2\n",
      "#bunzip2 1988.csv.bz2\n",
      "#bunzip2 1989.csv.bz2\n",
      "#bunzip2 1990.csv.bz2\n",
      "#bunzip2 1991.csv.bz2\n",
      "#bunzip2 1992.csv.bz2\n",
      "#bunzip2 1993.csv.bz2\n",
      "#bunzip2 1994.csv.bz2\n",
      "#bunzip2 1995.csv.bz2\n",
      "#bunzip2 1996.csv.bz2\n",
      "#bunzip2 1997.csv.bz2\n",
      "#bunzip2 1998.csv.bz2\n",
      "#bunzip2 1999.csv.bz2\n",
      "#bunzip2 2000.csv.bz2\n",
      "#bunzip2 2001.csv.bz2\n",
      "#bunzip2 2002.csv.bz2\n",
      "#bunzip2 2003.csv.bz2\n",
      "#bunzip2 2004.csv.bz2\n",
      "#bunzip2 2005.csv.bz2\n",
      "#bunzip2 2006.csv.bz2\n",
      "#bunzip2 2007.csv.bz2\n",
      "#bunzip2 2008.csv.bz2\n",
      "#sqlite3 ontime.sqlite3\n",
      "#create table ontime (Year int, Month int, DayofMonth int, DayOfWeek int, DepTime int, CRSDepTime int, ArrTime int, CRSArrTime int, UniqueCarrier varchar(5), FlightNum int, TailNum varchar(8), ActualElapsedTime int, CRSElapsedTime int, AirTime int, ArrDelay int, DepDelay int, Origin varchar(3), Dest varchar(3), Distance int, TaxiIn int, TaxiOut int, Cancelled int, CancellationCode varchar(1), Diverted varchar(1), CarrierDelay int, WeatherDelay int, NASDelay int, SecurityDelay int, LateAircraftDelay int);\n",
      "#.separator ,\n",
      "#.import 2008.csv\n",
      "#.import 2007.csv\n",
      "#.import 2006.csv\n",
      "#.import 2005.csv\n",
      "#.import 2004.csv\n",
      "#.import 2003.csv\n",
      "#.import 2002.csv\n",
      "#.import 2001.csv\n",
      "#.import 2000.csv\n",
      "#.import 1999.csv\n",
      "#.import 1998.csv\n",
      "#.import 1997.csv\n",
      "#.import 1996.csv\n",
      "#.import 1995.csv\n",
      "#.import 1994.csv\n",
      "#.import 1993.csv\n",
      "#.import 1992.csv\n",
      "#.import 1991.csv\n",
      "#.import 1990.csv\n",
      "#.import 1989.csv\n",
      "#.import 1988.csv\n",
      "#.import 1987.csv\n",
      "#delete from ontime where typeof(year) == \"text\";\n",
      "#create index year on ontime(year);\n",
      "#create index origin on ontime(origin);\n",
      "#create index uniquecarrier on ontime(uniquecarrier);\n",
      "#create index month on ontime(month);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Creating the Database"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Due to the large size of the raw data, we could not work with it directly in iPython Notebook. Instead, we turned to SQLite to construct an SQL database. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Start sqlite3, create database**\n",
      "<br>$ sqlite3 ontime.sqlite3\n",
      "\n",
      "<br>\n",
      "**Create table**\n",
      "<br>sqlite> create table ontime (\n",
      "<br>   ...>   Year int,\n",
      "<br>   ...>   Month int,\n",
      "<br>   ...>   DayofMonth int,\n",
      "<br>   ...>   DayOfWeek int,\n",
      "<br>   ...>   DepTime  int,\n",
      "<br>   ...>   CRSDepTime int,\n",
      "<br>   ...>   ArrTime int,\n",
      "<br>   ...>   CRSArrTime int,\n",
      "<br>   ...>   UniqueCarrier varchar(5),\n",
      "<br>   ...>   FlightNum int,\n",
      "<br>   ...>   TailNum varchar(8),\n",
      "<br>   ...>   ActualElapsedTime int,\n",
      "<br>   ...>   CRSElapsedTime int,\n",
      "<br>   ...>   AirTime int,\n",
      "<br>   ...>   ArrDelay int,\n",
      "<br>   ...>   DepDelay int,\n",
      "<br>   ...>   Origin varchar(3),\n",
      "<br>   ...>   Dest varchar(3),\n",
      "<br>   ...>   Distance int,\n",
      "<br>   ...>   TaxiIn int,\n",
      "<br>   ...>   TaxiOut int,\n",
      "<br>   ...>   Cancelled int,\n",
      "<br>   ...>   CancellationCode varchar(1),\n",
      "<br>   ...>   Diverted varchar(1),\n",
      "<br>   ...>   CarrierDelay int,\n",
      "<br>   ...>   WeatherDelay int,\n",
      "<br>   ...>   NASDelay int,\n",
      "<br>   ...>   SecurityDelay int,\n",
      "<br>   ...>   LateAircraftDelay int\n",
      "<br>   ...> );\n",
      "\n",
      "<br>\n",
      "**Import the data from .csv**\n",
      "<br>sqlite> .separator ,\n",
      "<br>sqlite> .import 2008.csv ontime\n",
      "<br>sqlite> .import 2007.csv ontime\n",
      "<br>sqlite> .import 2006.csv ontime\n",
      "<br>sqlite> .import 2005.csv ontime\n",
      "<br>etc...\n",
      "\n",
      "<br>\n",
      "**Remove imported header rows**\n",
      "<br>sqlite> delete from ontime where typeof(year) == \"text\";\n",
      "\n",
      "<br>\n",
      "**Add some indices for convenience later**\n",
      "<br>sqlite> create index year on ontime(year);\n",
      "<br>sqlite> create index origin on ontime(origin);\n",
      "<br>sqlite> create index uniquecarrier on ontime(uniquecarrier);\n",
      "<br>sqlite> create index month on ontime(month);"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have a database with the relevant raw flight data we downloaded. We can now access the data in iPython Notebook via Python commands, using the sqlite3 package."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Narrowing it Down"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We don't want to look at all of the data, since it's not all relevant to our interests. We will narrow it down to fit the scope of our investigation. First of all, we are interested in classifying flights by their airport of origin. And we will look at the 20 airports with the most originating flights. So we produce a list of those airports as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3, csv\n",
      "database = sqlite3.connect('../data/raw/ontime.sqlite3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur = database.cursor()\n",
      "cur.execute('SELECT DISTINCT Origin FROM ontime')\n",
      "airports = cur.fetchall()\n",
      "flights = []\n",
      "for i in airports:\n",
      "    cur.execute('SELECT Count(*) FROM ontime WHERE (Origin = ?)', i)\n",
      "    flights.append((i[0], cur.fetchone()[0]))\n",
      "airport_flights = sorted(flights, key=lambda flight: flight[1], reverse=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_airports = []\n",
      "flight_total = 0\n",
      "for i in range (0, 20):\n",
      "    top_airports.append(airport_flights[i][0])\n",
      "    flight_total += airport_flights[i][1]\n",
      "print top_airports\n",
      "print flight_total\n",
      "\n",
      "print airport_flights[0][1]\n",
      "print airport_flights[19][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'ORD', u'ATL', u'DFW', u'LAX', u'PHX', u'DEN', u'DTW', u'IAH', u'MSP', u'SFO', u'STL', u'EWR', u'LAS', u'CLT', u'LGA', u'BOS', u'PHL', u'PIT', u'SLC', u'SEA']\n",
        "64067176\n",
        "6597442\n",
        "1984077\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above, you see a list of the top 20 airports, and the total number of flights that originate from those airports. These represent just over half of the total flights from 1987-2008.\n",
      "\n",
      "We'll also look at the top 5 airlines:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur = database.cursor()\n",
      "cur.execute('SELECT DISTINCT UniqueCarrier FROM ontime')\n",
      "airlines = cur.fetchall()\n",
      "flights = []\n",
      "for i in airlines:\n",
      "    cur.execute('SELECT Count(*) FROM ontime WHERE (UniqueCarrier = ?)', i)\n",
      "    flights.append((i[0], cur.fetchone()[0]))\n",
      "airline_flights = sorted(flights, key=lambda flight: flight[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_airlines = []\n",
      "flight_total = 0\n",
      "for i in range (0, 5):\n",
      "    top_airlines.append(airline_flights[i][0])\n",
      "    flight_total += airline_flights[i][1]\n",
      "print top_airlines\n",
      "print flight_total"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'DL', u'WN', u'AA', u'US', u'UA']\n",
        "74883886\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we gather the relevant data into .csv files. For each airport we care about, we will find all flights originating there, and get the year, month, departure delay, cancellation status, and cancellation code for each flight."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#writes the necessary csvs for airports\n",
      "\n",
      "for i in range (0, 20):\n",
      "    cur.execute('SELECT Origin, Year, Month, DepDelay, Cancelled, CancellationCode FROM ontime WHERE (Origin = ?)', (airport_flights[i][0],))\n",
      "    writer = csv.writer(open(\"../data/raw/%s.csv\" % airport_flights[i][0], \"w\"))\n",
      "    writer.writerows(cur)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Same as above, except for the airlines rather than airports."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#writes the necessary csvs for airlines\n",
      "\n",
      "for i in range (0, 5):\n",
      "    cur.execute('SELECT UniqueCarrier, Year, Month, DepDelay, Cancelled, CancellationCode FROM ontime WHERE (UniqueCarrier = ?)', (airline_flights[i][0],))\n",
      "    writer = csv.writer(open(\"../data/raw/%s.csv\" % airline_flights[i][0], \"w\"))\n",
      "    writer.writerows(cur)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that while we have saved these files into the cleaned folder, they aren't completely cleaned yet. See next notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}